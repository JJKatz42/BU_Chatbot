{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answers queries based on Weaviate db search\n",
    "### 1. Search the weaviate database for the top k most relevent textContent objects using a hybrid search\n",
    "### 2. Build a string of context to be fed into the reasoning llm\n",
    "### 3. Insert the context into the llm and format the answer properly\n",
    "### 4. Print result to the console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import html2text\n",
    "import openai\n",
    "\n",
    "\n",
    "WEAV_CLUSTER_URL = \"https://bu-cluster-2-o5pekqq0.weaviate.network\"\n",
    "WEAV_API_KEY = \"vXNsRxv6vSJ57r0JKOJxhlBwMDIBadbyvjGC\"\n",
    "OPENAI_API_KEY = \"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\"\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "\n",
    "# helper function to print json in a pretty way\n",
    "def prettify(json_dict: dict) -> None:\n",
    "    \"\"\"\n",
    "    This function prints a JSON dictionary in a pretty way.\n",
    "\n",
    "    Args:\n",
    "        json_dict: A JSON dictionary\n",
    "    \"\"\"\n",
    "    print(json.dumps(json_dict, indent=2))\n",
    "\n",
    "\n",
    "def connect_to_weaviate(weav_cluster_url: str, weav_api_key: str, openAI_api_key: str) -> weaviate.Client:\n",
    "    \"\"\"\n",
    "    This function connects to a Weaviate instance.\n",
    "\n",
    "    Args:\n",
    "        None\n",
    "    \"\"\"\n",
    "    client = weaviate.Client(\n",
    "        url=weav_cluster_url,  \n",
    "        auth_client_secret=weaviate.AuthApiKey(api_key=weav_api_key),  \n",
    "        additional_headers={\n",
    "            \"X-OpenAI-Api-Key\": openAI_api_key\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return client\n",
    "\n",
    "\n",
    "def query_weaviate(client: weaviate.Client, prompt: str, top_k: int) -> dict:\n",
    "    \"\"\"\n",
    "    This function queries Weaviate for the most similar context to the prompt.\n",
    "    \n",
    "    Args:\n",
    "        prompt: The prompt to query Weaviate with\n",
    "        client: The Weaviate client\n",
    "        n: The number of results to return\n",
    "    \"\"\"\n",
    "\n",
    "    results = (\n",
    "        client.query\n",
    "            .get(\"Jonahs_weaviate_TextContent\", [\"text\", \"contentOf { ... on Jonahs_weaviate_Webpage { title } }\"])\n",
    "            .with_hybrid(\n",
    "                query=prompt,\n",
    "                alpha=0.75\n",
    "            )\n",
    "            .with_limit(top_k)\n",
    "            .do()\n",
    "    )\n",
    "\n",
    "    result_dict = {}\n",
    "\n",
    "    # Return the 'cleanText' property of the results\n",
    "    # print(results['data']['Get']['TextContent'])\n",
    "\n",
    "    for result in results['data']['Get']['Jonahs_weaviate_TextContent']:\n",
    "        result_dict[result['text']] = result['contentOf'][0]['title']\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "def get_answer(\n",
    "    client: weaviate.Client,\n",
    "    query: str,\n",
    "    top_k: int=3,\n",
    "    model: str=\"text-davinci-003\",\n",
    "    max_len_context: int=6000,\n",
    "    max_tokens_in_response: int=2000,\n",
    "    size: str=\"ada\",\n",
    "    debug: bool=False,\n",
    "    stop_sequence: str=None,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    This function answers a question based on a context.\n",
    "\n",
    "    Args:\n",
    "        client: The Weaviate client\n",
    "        query: The query to use to find the context\n",
    "        top_k: The number of results to use as context\n",
    "        model: The OpenAI model to use\n",
    "        max_len_context: The maximum length of the context\n",
    "        max_tokens_in_response: The maximum number of tokens in the response\n",
    "        size: The size of the model\n",
    "        debug: Whether to print debug information\n",
    "        stop_sequence: The sequence to stop the response at\n",
    "    \"\"\"\n",
    "\n",
    "    results = query_weaviate(client=client, prompt=query, top_k=top_k)\n",
    "\n",
    "    count = 0\n",
    "    context = \"\"\n",
    "    for result in results.keys():\n",
    "        if count >= top_k:\n",
    "            break\n",
    "        else:\n",
    "            context += result + \"\\n\"\n",
    "            count += 1\n",
    "    \n",
    "    context = context[:max_len_context]\n",
    "    lst_sources = list(set(results.values()))[:top_k]\n",
    "\n",
    "    if debug:      \n",
    "        print(\"Context:\\n\" + context)\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    try:\n",
    "        # Create a response using the question and context\n",
    "        response = openai.Completion.create(\n",
    "            prompt=f\"Answer the question based on the context below, and if the question can't be answered based on the context, say \\\"I don't know\\\"\\n\\nContext: {context}\\n\\n---\\n\\nQuestion: {query}\\nAnswer: \\n\\n \",\n",
    "            temperature=0,\n",
    "            max_tokens=max_tokens_in_response,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=stop_sequence,\n",
    "            model=model,\n",
    "        )\n",
    "        answer = response[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "        full_answer = f\"Question: {query}\\n\\nAnswer: {answer}\\n\\nSource: {lst_sources}\\n\\n\"\n",
    "\n",
    "        return full_answer\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return \"\"\n",
    "    \n",
    "\n",
    "def print_answer(query: str) -> None:\n",
    "    \"\"\"\n",
    "    This function prints the answer to a query.\n",
    "\n",
    "    Args:\n",
    "        query: The query to answer\n",
    "    \"\"\"\n",
    "\n",
    "    # Connect to Weaviate\n",
    "    weav_client = connect_to_weaviate(weav_cluster_url=WEAV_CLUSTER_URL, weav_api_key=WEAV_API_KEY, openAI_api_key=OPENAI_API_KEY)\n",
    "\n",
    "    # Answer the query\n",
    "    answer = get_answer(client=weav_client, query=query, top_k=3, model=\"text-davinci-003\")\n",
    "\n",
    "    # Print the answer\n",
    "    print(answer)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print_answer(\"How do I know if I need to be covered by health insurance?\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
