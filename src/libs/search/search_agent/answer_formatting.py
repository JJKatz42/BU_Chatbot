import re

import langchain.chat_models
import langchain.schema

import src.libs.search.search_agent.schemas as schemas
import src.libs.search.search_agent.utils as utils
import src.libs.logging as logging

logger = logging.getLogger(__name__)


instructions_msg = langchain.prompts.SystemMessagePromptTemplate.from_template(
    template="You are tasked with ensuring that an answer that was generated by an LLM is formatted correctly. "
    "Your task is to ensure that the answer is formatted according to **ALL** the following rules. If the answer "
    "is already formatted correctly, please leave it as is.\n\n"
    "Rule 1. Ensure that crucial or definitive parts of the answer are wrapped in asterisks like *this*.\n"
    "Rule 2. The answer must start with '{answer_prefix}'.\n"
    "Rule 3. If the question requests a list of items, the answer should contain a bulleted list of items "
    "appropriate to the question.",
    template_format="f-string",
)

# TODO: implement some version of the following, which fail miserably in testing with gpt-3.5-turbo
#   "Rule X. If the original question asks for a specific tone or style, the answer should be written in that tone or "
#   "style.  For example if the question asks 'written in the style of shakespear', please reformat the entire answer "
#   "in the style of shakespear.  This is allowed to break Rule 3, as well as Rule 1 as long as it remains generally "
#   "safe for a workplace environment.\n"


question_msg_prompt_tmpl = langchain.prompts.HumanMessagePromptTemplate.from_template(
    template="Question: {question}", template_format="f-string"
)

generated_answer_msg_prompt_tmpl = langchain.prompts.HumanMessagePromptTemplate.from_template(
    template="Answer: {answer}", template_format="f-string"
)

instructions_reminder_msg = langchain.schema.SystemMessage(
    content="Please re-format the answer based on **ALL** the formatting rules."
)


def build_format_answer_prompt_msgs(
    generated_answer: str,
    sources: list[schemas.SearchResult],
    question: str,
) -> list[langchain.prompts.base.BaseMessage]:
    # Set answer prefix
    answer_prefix = "Based on the provided sources, " if len(sources) > 1 else "Based on the provided source, "

    prompt_messages = [
        instructions_msg.format(answer_prefix=answer_prefix),
        question_msg_prompt_tmpl.format(question=question),
        generated_answer_msg_prompt_tmpl.format(answer=generated_answer),
        instructions_reminder_msg,
    ]

    return prompt_messages


@utils.llm_schema_gen_retry_config
async def format_answer(
    generated_answer: str,
    llm: langchain.chat_models.ChatOpenAI,
    fallback_llm: langchain.chat_models.ChatOpenAI,
    query: str,
    sources: list[schemas.SearchResult],
    max_answer_tokens: int = 500,
):
    """Format the answer and excerpt generated by an LLM.

    Operates in-place on the generated_answer.

    Args:
        generated_answer: The answer and excerpt generated by an LLM.
        llm: The LLM to use for formatting the answer and excerpt.
        fallback_llm: The fallback LLM to use for formatting the answer and excerpt if the primary LLM is not
            appropriate for the prompt.
        query: The query that was used to generate the answer and excerpt.
        sources: The sources that were used to generate the answer and excerpt.
        max_answer_tokens: The maximum number of tokens to use for the primary LLM before using the fallback

    Returns:
        None
    """
    prompt_msgs = build_format_answer_prompt_msgs(
        generated_answer=generated_answer,
        sources=sources,
        question=query,
    )

    llm_to_use = utils.get_llm_to_use(prompt_msgs, llm, fallback_llm, max_answer_tokens)
    llm_answer_response_message = await llm_to_use.apredict_messages(
        messages=prompt_msgs,
        request_timeout=15,
    )

    # Updated the generated answer
    formatted_answer = llm_answer_response_message.content

    return formatted_answer

    # Ensure links are formatted properly in the answer and excerpt
    # generated_answer.answer = replace_markdown_links_with_slack_format_links(generated_answer.answer)
    # if generated_answer.excerpt:
    #     generated_answer.excerpt = replace_markdown_links_with_slack_format_links(generated_answer.excerpt)
    #
    # # Ensure source titles are formatted properly as links in the answer
    # for source in sources:
    #     generated_answer.answer = replace_source_title_or_link_with_slack_format_link(generated_answer.answer, source)


# def replace_markdown_links_with_slack_format_links(markdown_text: str) -> str:
#     """Modify Markdown links to be in the format <link|text>"""
#     return re.sub(r"\[([^\]]+)\]\(([^)]+)\)", r"<\2|\1>", markdown_text)

#
# def replace_source_title_or_link_with_slack_format_link(markdown_text: str, source: schemas.SearchResult) -> str:
#     """Replace the source title or link with a Slack markdown link.
#
#     Args:
#         markdown_text: The markdown text to modify
#         source: The source to use for the link
#
#     Returns:
#         The modified markdown text
#     """
#     # If the source doesn't have a title or a source url, return the original markdown text
#     if not source.document_source_info or not source.document_source_info.title:
#         return markdown_text
#
#     # Create the Slack markdown link from the source title and url which will be used to replace the title and url
#     slack_md_link = f"<{source.document_source_info.source_url}|{source.document_source_info.title}>"
#
#     # Step 1: Replace existing Slack markdown links with a placeholder. This is to prevent the existing Slack markdown
#     # links from being replaced in the next steps. We will replace the placeholders back to the Slack markdown links
#     # in the last step.
#     placeholder = "PLACEHOLDER1234567890XYZ"
#     markdown_text = markdown_text.replace(slack_md_link, placeholder)
#
#     # Step 2: Replace all occurrences of title and url with the Slack markdown link
#     markdown_text = re.sub(
#         rf"(?<!<){re.escape(source.document_source_info.source_url)}(?!>)", slack_md_link, markdown_text
#     )
#     markdown_text = re.sub(rf"(?<!<){re.escape(source.document_source_info.title)}(?!>)", slack_md_link, markdown_text)
#
#     # Step 3: Replace placeholders back to the Slack markdown link
#     markdown_text = markdown_text.replace(placeholder, slack_md_link)
#     return markdown_text
